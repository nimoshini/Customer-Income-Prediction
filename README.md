ğŸ“Š CENSUS INCOME PREDICTION ANALYSIS
ğŸ“Œ Dataset Overview
The Census Income Dataset contains demographic and employment details of individuals. The goal is to predict whether a person earns more than $50K per year based on given attributes.

ğŸ”¹ Target Variable:
âœ… <=50K (Encoded as 0)
âœ… >50K (Encoded as 1)

DATASET FEATURES
ğŸ”¢ Numerical Features
age: Individualâ€™s age.

fnlwgt: Final weight assigned to observation.

education-num: Number of years of education.

capital-gain: Capital gain in income.

capital-loss: Capital loss in income.

hours-per-week: Weekly working hours.

ğŸ”  Categorical Features
workclass: Type of employer (e.g., Private, Government).

education: Education level (e.g., Bachelors, HS-grad).

marital-status: Marital status (e.g., Married, Single).

occupation: Type of job (e.g., Tech-support, Sales).

relationship: Family role (e.g., Husband, Wife).

race: Ethnicity of the individual.

sex: Gender of the individual.

native-country: Country of origin.

ğŸ“Œ Note: All categorical features were label-encoded before training the models.

ğŸš€ MODEL PERFORMANCE SUMMARY

Implemented three machine learning models for classification:

ğŸ“‰ Logistic Regression	              82.79%
ğŸŒ³ Decision Tree	              86.00%
ğŸŒ² Random Forest	              86.44%

ğŸ”¬ MODEL ANALYSIS

ğŸ“‰ Logistic Regression
ğŸ“Œ Description:

A linear model using the sigmoid function to estimate class probabilities.

It is highly interpretable, making it easy to see feature impacts.

ğŸ“‰ Limitations:

Assumes a linear relationship between features and target variable.

Struggles with complex patterns in data.

âœ” Accuracy: 82.79% (Lowest among models)

ğŸŒ³ Decision Tree Classifier (Optimized max_depth)
ğŸ“Œ Description:

Splits data based on feature conditions.

Captures non-linear relationships and is easy to interpret.

ğŸ“Œ Optimization:

Tested max_depth from 1 to 20 using brute force to find the best value.

âš ï¸ Limitations:

Overfitting risk if depth is too high.

Sensitive to small changes in data.

âœ” Best max_depth: Found through brute force.
âœ” Accuracy: 86.00%

ğŸŒ² Random Forest Classifier (Using GridSearchCV for Best Parameters)
ğŸ“Œ Description:

An ensemble model that builds multiple Decision Trees and combines outputs.

Reduces overfitting and improves accuracy.

ğŸ“Œ Hyperparameter Tuning (Using GridSearchCV):

n_estimators (Number of trees): 50, 100, 200

max_depth: 10, 20, 30

min_samples_split: 2, 5, 10

ğŸ“Œ Best Parameters Found:
âœ” n_estimators: 200
âœ” max_depth: 20
âœ” min_samples_split: 5

ğŸš€ Advantages:
âœ… More robust than a single Decision Tree.
âœ… Handles imbalanced data well.

âš ï¸ Limitations:

Computationally expensive for large datasets.

Less interpretable than a single Decision Tree.

âœ” Accuracy: 86.44% (Highest Performance)

ğŸ† CONCLUSION: Best Model Selection
âœ… Random Forest is the best-performing model with an accuracy of 86.44%.
âœ… It effectively captures complex data patterns and prevents overfitting.
âœ… GridSearchCV optimized hyperparameters improved performance.

ğŸš€ Final Recommendation: Use Random Forest for the best accuracy.
